{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion dataset\n",
    "# DenseNet Application of Image Classification\n",
    "## Multi label problem\n",
    "The data is from the kaggle competition [iMaterialist Challenge (Fashion) at FGVC5](https://www.kaggle.com/c/imaterialist-challenge-fashion-2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.densenet import densenet121 as feature_extractor\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE = 256\n",
    "TRAIN = \"/data/fashion/img/train/\"\n",
    "VALID = \"/data/fashion/img/valid/\"\n",
    "CUDA = torch.cuda.is_available()\n",
    "DENSE_FEATURE = 1024\n",
    "BS = 32\n",
    "# VERSION = \"0.0.1\" # bias =True for last linear\n",
    "VERSION = \"0.0.2\"\n",
    "CATE_LEN = 228\n",
    "\n",
    "# Mean and standard for normalization\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "conv_model = feature_extractor(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split ConvLayer to 2 parts, conv0~transtition3, (not gonna train), denseblock4~norm5 (train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_conv1 = nn.Sequential(*[getattr(conv_model.features,nn_name) for nn_name in [\"conv0\",\"norm0\",\"relu0\",\"pool0\",\"denseblock1\",\"transition1\",\n",
    "                                                                                   \"denseblock2\",\"transition2\",\"denseblock3\",\"transition3\",]])\n",
    "\n",
    "dense_conv2 = nn.Sequential(*[getattr(conv_model.features,nn_name) for nn_name in [\"denseblock4\",\"norm5\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.RandomAffine([-10,10]), \n",
    "                                transforms.Resize((SCALE,SCALE)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(MEAN,STD),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fashion_data(Dataset):\n",
    "    def __init__(self,img_folder,cate_len,transform):\n",
    "        super(fashion_data,self).__init__()\n",
    "        self.img_folder = img_folder\n",
    "        self.fnames = os.listdir(self.img_folder)\n",
    "        self.cate_len = cate_len\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def get_cate(self,url):\n",
    "        zr = torch.zeros(228)\n",
    "        zr[torch.LongTensor(list(int(i[1:])-1 for i in str(url).split(\".\")[0].split(\"_\")[1:]))]=1\n",
    "        return zr\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img = Image.open(self.img_folder+self.fnames[idx]).convert(\"RGB\")\n",
    "        img = self.transform(img)\n",
    "        return img, self.get_cate(self.fnames[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn = fashion_data(TRAIN,CATE_LEN,transform = transform)\n",
    "# dl = DataLoader(trn,batch_size=4,shuffle=4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASS_TO_IDX = trn.class_to_idx\n",
    "# IDX_TO_CLASS = dict((v,k) for k,v in CLASS_TO_IDX.items())\n",
    "# print(IDX_TO_CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_gen = iter(DataLoader(trn,shuffle=True))\n",
    "\n",
    "# next(data_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top half of the model, with fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten,self).__init__()\n",
    "    def forward(self,x):\n",
    "        bs = x.size()[0]\n",
    "        return x.view(bs,-1)\n",
    "    \n",
    "def convlayer(f_in,f_out,ks,stride=1):\n",
    "    return nn.Sequential(*[\n",
    "        nn.Conv2d(f_in, f_out, ks, stride = stride, padding = ks//2,bias = True),\n",
    "        nn.BatchNorm2d(f_out),\n",
    "        nn.LeakyReLU(inplace = True),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "fl = Flatten()\n",
    "FEATURE_WIDTH = dense_conv2(dense_conv1(torch.rand(2,3,SCALE,SCALE))).size()[1]\n",
    "print(FEATURE_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class top_half(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(top_half,self).__init__()\n",
    "        self.top_ = nn.Sequential(*[\n",
    "                                    convlayer(FEATURE_WIDTH,FEATURE_WIDTH//2,3,2),\n",
    "                                    convlayer(FEATURE_WIDTH//2,FEATURE_WIDTH//4,3,2),\n",
    "                                    Flatten(),\n",
    "                                    nn.Linear(FEATURE_WIDTH,DENSE_FEATURE,bias=False),\n",
    "                                    nn.BatchNorm1d(DENSE_FEATURE),\n",
    "                                    nn.LeakyReLU(inplace=True),\n",
    "                                    nn.Dropout(p=.5),\n",
    "                                    nn.Linear(DENSE_FEATURE,CATE_LEN,bias=False),\n",
    "                                   ])\n",
    "    def forward(self,x):\n",
    "        return self.top_(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Model, optimizer,train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_half_ = top_half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA:\n",
    "    torch.cuda.empty_cache()\n",
    "    top_half_.cuda()\n",
    "    dense_conv1.cuda()\n",
    "    dense_conv2.cuda()\n",
    "    \n",
    "from torch.optim import Adam\n",
    "\n",
    "opt = Adam(list(dense_conv2.parameters())+list(top_half_.parameters()),amsgrad=True)\n",
    "# loss_func = nn.CrossEntropyLoss()\n",
    "loss_func = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from p3self.matchbox import Trainer,argmax,accuracy,supermean,f1_score,save_model,load_model\n",
    "\n",
    "def save_():\n",
    "    save_model(dense_conv2,\"/data/weights/dense_conv2.%s.pkl\"%(VERSION))\n",
    "    save_model(top_half_,\"/data/weights/top_half.%s.pkl\"%(VERSION))\n",
    "    \n",
    "def load_():\n",
    "    load_model(dense_conv2,\"/data/weights/dense_conv2.%s.pkl\"%(VERSION))\n",
    "    load_model(top_half_,\"/data/weights/top_half.%s.pkl\"%(VERSION))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(trn,batch_size=BS,print_on=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(*args,**kwargs):\n",
    "    x,y = args[0]\n",
    "    if CUDA:\n",
    "        x,y = x.cuda(),y.cuda()\n",
    "    x = x[:,:3,...]\n",
    "    opt.zero_grad()\n",
    "    y_ = top_half_(dense_conv2(dense_conv1(x)))\n",
    "    \n",
    "    loss = loss_func(y_,y)\n",
    "    acc,recall,precision,f1 = f1_score(y_,y)\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if kwargs[\"ite\"]%10==9:\n",
    "        save_()\n",
    "    return {\n",
    "        \"loss\":loss.item(),\n",
    "        \"acc\":acc.item(),\n",
    "        \"recall\":recall.item(),\n",
    "        \"precision\":precision.item(),\n",
    "        \"f1\":f1.item(),\n",
    "    }\n",
    "    \n",
    "def val_action(*args,**kwargs):\n",
    "    x,y = args[0]\n",
    "    if CUDA:\n",
    "        x,y = x.cuda(),y.cuda()\n",
    "    x = x[:,:3,...]\n",
    "    y_ = top_half_(dense_conv2(dense_conv1(x)))\n",
    "    \n",
    "    loss = loss_func(y_,y)\n",
    "    accuracy,recall,precision,f1 = f1_score(y_,y)\n",
    "\n",
    "    return {\n",
    "        \"loss\":loss.item(),\n",
    "        \"acc\":acc.item(),\n",
    "        \"recall\":recall.item(),\n",
    "        \"precision\":precision.item(),\n",
    "        \"f1\":f1.item(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.action = action\n",
    "# trainer.val_action = val_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⭐[ep_0_i_3534]\tacc\t0.982✨\tf1\t0.501✨\tloss\t0.056✨\tprecision\t0.762✨\trecall\t0.374:  11%|█         | 3538/31655 [1:00:36<8:01:38,  1.03s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
